{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e818f04-a142-4540-a1dc-6e473455106d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open_clip_torch\n",
      "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (4.66.5)\n",
      "Requirement already satisfied: pillow in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (10.4.0)\n",
      "Collecting torch>=1.9.0 (from open_clip_torch)\n",
      "  Downloading torch-2.7.1-cp39-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting torchvision (from open_clip_torch)\n",
      "  Downloading torchvision-0.22.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting regex (from open_clip_torch)\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ftfy (from open_clip_torch)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting huggingface-hub (from open_clip_torch)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting safetensors (from open_clip_torch)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting timm (from open_clip_torch)\n",
      "  Downloading timm-1.0.17-py3-none-any.whl.metadata (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.4)\n",
      "Collecting fsspec (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: wcwidth in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from ftfy->open_clip_torch) (0.2.5)\n",
      "Requirement already satisfied: packaging>=20.9 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from huggingface-hub->open_clip_torch) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from huggingface-hub->open_clip_torch) (6.0.1)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub->open_clip_torch)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from torchvision->open_clip_torch) (1.26.4)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.9.0->open_clip_torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/envs/python_3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open_clip_torch) (2024.12.14)\n",
      "Downloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp39-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.17-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.1-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, safetensors, regex, networkx, hf-xet, ftfy, fsspec, filelock, torch, huggingface-hub, torchvision, timm, open_clip_torch\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 ftfy-6.3.1 hf-xet-1.1.5 huggingface-hub-0.33.4 mpmath-1.3.0 networkx-3.2.1 open_clip_torch-2.32.0 regex-2024.11.6 safetensors-0.5.3 sympy-1.14.0 timm-1.0.17 torch-2.7.1 torchvision-0.22.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install open_clip_torch tqdm pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fc3417-cee9-45a8-ae8a-01e21088ac02",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/your/project'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m IMG_ROOT   \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(WORK_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_images\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 画像の親フォルダ\u001b[39;00m\n\u001b[1;32m      9\u001b[0m DATA_DIR   \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(WORK_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)             \u001b[38;5;66;03m# image_paths.txt などがある場所\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWORK_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ==== デバイス ====\u001b[39;00m\n\u001b[1;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/your/project'"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import open_clip\n",
    "\n",
    "# ==== パス設定 ====\n",
    "WORK_DIR   = \"/path/to/your/project\"          # 作業ディレクトリ\n",
    "IMG_ROOT   = os.path.join(WORK_DIR, \"training_images\")  # 画像の親フォルダ\n",
    "DATA_DIR   = os.path.join(WORK_DIR, \"data\")             # image_paths.txt などがある場所\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "# ==== デバイス ====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ==== CLIPモデル ====\n",
    "clip_model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    'ViT-B-32', pretrained='laion2b_s34b_b79k', device=device\n",
    ")\n",
    "clip_model.eval()\n",
    "CLIP_DIM = clip_model.visual.output_dim\n",
    "print(\"device:\", device, \"clip dim:\", CLIP_DIM)\n",
    "from pathlib import Path\n",
    "for p in Path.home().glob(\"Library/CloudStorage/GoogleDrive*\"):\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "587bb10a-c3ed-4cfd-9c2a-6670f8068d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "for p in Path.home().glob(\"Library/CloudStorage/GoogleDrive*\"):\n",
    "    print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86eff03e-11a8-4594-98ef-3a3a72e3e645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images -> /Users/teraimao/training_images | exists: False\n",
      "data/train/image_paths.txt -> /Users/teraimao/data/train/image_paths.txt | exists: False\n",
      "data/val/image_paths.txt -> /Users/teraimao/data/val/image_paths.txt | exists: False\n"
     ]
    }
   ],
   "source": [
    "# 必要なファイル/フォルダが本当にあるかを一発チェック\n",
    "targets = [\n",
    "    \"training_images\",\n",
    "    \"data/train/image_paths.txt\",\n",
    "    \"data/val/image_paths.txt\"\n",
    "]\n",
    "for t in targets:\n",
    "    p = Path(t).expanduser().resolve()\n",
    "    print(f\"{t} -> {p} | exists: {p.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13710f5c-3d59-4a09-a01b-450afb3ab9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
